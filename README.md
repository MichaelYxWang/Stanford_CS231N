# Stanford_CS231N
The goal of setting up this repo is to make full use of Stanford CS 231N course.

This repo mainly provides the following features:
1. For review purpose : A more convenient visualization of jupyter notebooks without setting up notebook server locally.
2. The references of papers which appear in the 5 courses as well as some notes about the papers
3. Nicely commented code from helper functions to project architecture as well as a guideline of how to go through them
4. Extend the project to end to end system: from data labeling to research diary

Recourse collection contributors: [Michael Wang](https://github.com/MichaelYxWang)


### Lecture 2 - Image Classification Pipeline:
**[1]** "Deep Visual-Semantic Alignments for Generating Image Descriptions"[[pdf]](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)


### Lecture 3 - Loss Functions and Optimization:
**[1]** "Object Recognition from Local Scale-Invariant Features"[[pdf]](https://www.cs.ubc.ca/~lowe/papers/iccv99.pdf)

**[2]** "Histograms of Oriented Gradients for Human Detection"[[pdf]](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)

**[3]** "A Bayesian Hierarchical Model for Learning Natural Scene Categories"[[pdf]](http://vision.stanford.edu/documents/Fei-FeiPerona2005.pdf)


### Lecture 4 - Backpropagation and Neural Networks:
**[1]** "Object Recognition from Local Scale-Invariant Features"[[pdf]](https://www.cs.ubc.ca/~lowe/papers/iccv99.pdf)

**[2]** "Histograms of Oriented Gradients for Human Detection"[[pdf]](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)


### Lecture 5 - Convolutional Neural Networks:
**[1]** "ImageNet Classification with Deep Convolutional
Neural Networks"[[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

**[2]** "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"[[pdf]](https://arxiv.org/pdf/1506.01497.pdf)

**[3]** "DeepFace: Closing the Gap to Human-Level Performance in Face Verification"[[pdf]](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)

**[4]** "Deep Inside Convolutional Networks: Visualising
Image Classification Models and Saliency Maps"[[pdf]](https://arxiv.org/pdf/1312.6034.pdf)

**[5]** "Two-Stream Convolutional Networks for Action Recognition in Videos"[[pdf]](https://arxiv.org/pdf/1406.2199.pdf)

**[6]** "DeepPose: Human Pose Estimation via Deep Neural Networks"[[pdf]](https://arxiv.org/pdf/1312.4659.pdf)

**[7]** "Deep Learning for Real-Time Atari Game Play
Using Offline Monte-Carlo Tree Search Planning"[[pdf]](https://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf)

**[8]** "Breast Mass Classification from Mammograms using
Deep Convolutional Neural Networks"[[pdf]](https://arxiv.org/pdf/1612.00542.pdf)

**[9]** "Rotation-invariant convolutional neural networks for galaxy
morphology prediction"[[pdf]](https://arxiv.org/pdf/1503.07077.pdf)

**[10]** "Traffic Sign Recognition with Multi-Scale Convolutional Networks"[[pdf]](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf)

**[11]** "Image Style Transfer Using Convolutional Neural Networks"[[pdf]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)

**[12]** "Controlling Perceptual Factors in Neural Style Transfer"[[pdf]](https://arxiv.org/pdf/1611.07865.pdf)


### Lecture 6 - Training Neural Networks I:
**[1]**  Papers on weight initializations are on the lecture slide.

**[2]** "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"[[pdf]](https://arxiv.org/pdf/1502.03167.pdf)


### Lecture 7 - Training Neural Networks II:
**[1]** "On the importance of initialization and momentum in deep learning"[[pdf]](http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)

**[2]** "Adaptive Subgradient Methods for
Online Learning and Stochastic Optimization"[[pdf]](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)

**[3]** "ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION"[[pdf]](https://arxiv.org/pdf/1412.6980.pdf)

**[4]** "On Optimization Methods for Deep Learning"[[pdf]](https://ai.stanford.edu/~ang/papers/icml11-OptimizationForDeepLearning.pdf)

**[5]** "SGDR: STOCHASTIC GRADIENT DESCENT WITH
WARM RESTARTS"[[pdf]](https://arxiv.org/pdf/1608.03983.pdf)

**[6]** "SNAPSHOT ENSEMBLES: TRAIN 1, GET M FOR FREE"[[pdf]](https://arxiv.org/pdf/1704.00109.pdf)

**[7]** "ACCELERATION OF STOCHASTIC APPROXIMATION BY AVERAGING*"[[pdf]](http://www.meyn.ece.ufl.edu/archive/spm_files/Courses/ECE555-2011/555media/poljud92.pdf)

**[8]** "Regularization of Neural Networks using DropConnect*"[[pdf]](http://yann.lecun.com/exdb/publis/pdf/wan-icml-13.pdf)

**[9]** "Deep Networks with Stochastic Depth"[[pdf]](https://arxiv.org/pdf/1603.09382.pdf)

**[10]** "DeCAF: A Deep Convolutional Activation Feature
for Generic Visual Recognition"[[pdf]](https://arxiv.org/pdf/1310.1531.pdf)

**[11]** "DeCAF: A Deep Convolutional Activation Feature
for Generic Visual Recognition"[[pdf]](https://arxiv.org/pdf/1310.1531.pdf)

**[12]** "Fast RCNN"[[pdf]](https://arxiv.org/pdf/1504.08083.pdf)



### Lecture 8 - Deep Learning Software:
**[1]** "DEEP LEARNING WITH DYNAMIC COMPUTATION GRAPHS"[[pdf]](https://arxiv.org/pdf/1702.02181.pdf)

**[2]** "Deep Compositional Question Answering with Neural Module Networks"[[pdf]](https://arxiv.org/pdf/1511.02799.pdf)

**[3]** "Learning to Compose Neural Networks for Question Answering"[[pdf]](https://arxiv.org/pdf/1601.01705.pdf)


### Lecture 9 - CNN Architectures:
**[1]** "ImageNet Classification with Deep Convolutional
Neural Networks(AlexNet)"[[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

**[2]** "Visualizing and Understanding Convolutional Networks"[[pdf]](https://arxiv.org/pdf/1311.2901.pdf)

**[3]** "VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION (VGG)"[[pdf]](https://arxiv.org/pdf/1409.1556.pdf)

**[4]** "Going deeper with convolutions (Google Net, Inception Net)"[[pdf]](https://arxiv.org/pdf/1409.4842.pdf)

**[5]** "Deep Residual Learning for Image Recognition (ResNet)"[[pdf]](https://arxiv.org/pdf/1512.03385.pdf)

**[6]** "Network in Network (NiN)"[[pdf]](https://arxiv.org/pdf/1312.4400.pdf)

**[7]** "Wide Residual Networks"[[pdf]](https://arxiv.org/pdf/1605.07146.pdf)

**[8]** "Aggregated Residual Transformations for Deep Neural Networks (ResNext)"[[pdf]](https://arxiv.org/pdf/1611.05431.pdf)

**[9]** "Wide Residual Networks"[[pdf]](https://arxiv.org/pdf/1605.07146.pdf)

**[10]** "Deep Networks with Stochastic Depth"[[pdf]](https://arxiv.org/pdf/1603.09382.pdf)

**[11]** "FRACTALNET: ULTRA-DEEP NEURAL NETWORKS WITHOUT RESIDUALS"[[pdf]](https://arxiv.org/pdf/1605.07648.pdf)

**[12]** "Densely Connected Convolutional Networks"[[pdf]](https://arxiv.org/pdf/1608.06993.pdf)

**[13]** "SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND <0.5MB MODEL SIZE"[[pdf]](https://arxiv.org/pdf/1602.07360.pdf)
