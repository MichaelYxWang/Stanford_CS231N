{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set up for the project\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import os\n",
    "project_dir = os.getcwd()\n",
    "model_dir = project_dir + \"/models/\"\n",
    "\n",
    "vgg_model_loc = model_dir + \"vgg11.h5\"\n",
    "vgg_json_loc = model_dir + \"vgg11.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Testing data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Get the original dimension of dataset\n",
    "(X_train_orig, Y_train), (X_test_orig, Y_test) = mnist.load_data()\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Testing data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Cut the traning and testing set by 1/10 to reduce operation time\n",
    "num_train = 60000\n",
    "mask_train = range(num_train)\n",
    "X_train_orig = X_train_orig[mask_train]\n",
    "Y_train = Y_train[mask_train]\n",
    "\n",
    "num_test = 10000\n",
    "mask_test = range(num_test)\n",
    "X_test_orig = X_test_orig[mask_test]\n",
    "Y_test = Y_test[mask_test]\n",
    "\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four randomly-chosen numbers are: 51006 59806 2371 4889\n",
      "The size of the 4 randomly-chosen images are:  (32, 32) (32, 32) (32, 32) (32, 32)\n",
      "The corresponding labels for the 4 images are: 0 1 9 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEOId7PgIId7x/zHA60BloxoLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146cd198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resize all images in training and test sets\n",
    "X_train = np.zeros((num_train,32,32))\n",
    "X_test = np.zeros((num_test,32,32))\n",
    "\n",
    "for i in range(num_train):\n",
    "    X_train[i] = imresize(X_train_orig[i],(32,32))\n",
    "\n",
    "for j in range(num_test):\n",
    "    X_test[j] = imresize(X_test_orig[j],(32,32))\n",
    "\n",
    "# Test with some random images\n",
    "a = random.randint(0,num_train)\n",
    "b = random.randint(0,num_train)\n",
    "c = random.randint(0,num_test)\n",
    "d = random.randint(0,num_test)\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[a], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[b], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_test[c], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_test[d], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "print(\"The four randomly-chosen numbers are:\", a,b,c,d)\n",
    "print(\"The size of the 4 randomly-chosen images are: \",X_train[a].shape, X_train[b].shape, \n",
    "                                                     X_test[c].shape, X_test[d].shape)\n",
    "print(\"The corresponding labels for the 4 images are:\", Y_train[a], Y_train[b], Y_train[c], Y_train[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 32, 32, 1)\n",
      "Training labels shape:  (60000, 10)\n",
      "Testing data shape:  (10000, 32, 32, 1)\n",
      "Test labels shape:  (10000, 10)\n",
      "Input shape:  (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "num_classes = 10\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Preprocessing: subtract the mean image\n",
    "train_mean = np.mean(X_train,axis=0)\n",
    "test_mean = np.mean(X_test,axis=0)\n",
    "X_train -= train_mean\n",
    "X_test -= test_mean\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)\n",
    "print(\"Input shape: \", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the VGG-11 model, VGG paper model A\n",
    "# Use same padding since the input shape(32,32,3) for this project is significantly smaller than that in the paper(224,224,3)\n",
    "def VGG_model():\n",
    "    model = Sequential()\n",
    "    regu = 5e-4\n",
    "    model.add(Conv2D(64,(3,3), input_shape=input_shape, padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "#     learning_rate = 0.01\n",
    "#     decay = learning_rate/epochs\n",
    "#     adam_customized = keras.optimizers.Adam(lr=learning_rate,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 28,186,634\n",
      "Trainable params: 28,164,746\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the vgg model\n",
    "vgg11_model = VGG_model()\n",
    "vgg11_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify the hyperparameters here\n",
    "batch_size = 512\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (60000, 32, 32, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  919/60000 [..............................] - ETA: 2689456s - loss: 0.5647 - acc: 0.9717"
     ]
    }
   ],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "vgg11_model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),steps_per_epoch=len(X_train), epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
