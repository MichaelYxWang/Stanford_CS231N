{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set up for the project\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import os\n",
    "project_dir = os.getcwd()\n",
    "model_dir = project_dir + \"/models/\"\n",
    "\n",
    "vgg_model_loc = model_dir + \"vgg11.h5\"\n",
    "vgg_json_loc = model_dir + \"vgg11.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Testing data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Get the original dimension of dataset\n",
    "(X_train_orig, Y_train), (X_test_orig, Y_test) = mnist.load_data()\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (25000, 28, 28)\n",
      "Training labels shape:  (25000,)\n",
      "Testing data shape:  (5000, 28, 28)\n",
      "Test labels shape:  (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Cut the traning and testing set by 1/10 to reduce operation time\n",
    "num_train = 25000\n",
    "mask_train = range(num_train)\n",
    "X_train_orig = X_train_orig[mask_train]\n",
    "Y_train = Y_train[mask_train]\n",
    "\n",
    "num_test = 5000\n",
    "mask_test = range(num_test)\n",
    "X_test_orig = X_test_orig[mask_test]\n",
    "Y_test = Y_test[mask_test]\n",
    "\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four randomly-chosen numbers are: 2865 2168 4 1037\n",
      "The size of the 4 randomly-chosen images are:  (32, 32) (32, 32) (32, 32) (32, 32)\n",
      "The corresponding labels for the 4 images are: 7 7 9 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146d6240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resize all images in training and test sets\n",
    "X_train = np.zeros((num_train,32,32))\n",
    "X_test = np.zeros((num_test,32,32))\n",
    "\n",
    "for i in range(num_train):\n",
    "    X_train[i] = imresize(X_train_orig[i],(32,32))\n",
    "\n",
    "for j in range(num_test):\n",
    "    X_test[j] = imresize(X_test_orig[j],(32,32))\n",
    "\n",
    "# Test with some random images\n",
    "a = random.randint(0,num_train)\n",
    "b = random.randint(0,num_train)\n",
    "c = random.randint(0,num_test)\n",
    "d = random.randint(0,num_test)\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[a], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[b], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_test[c], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_test[d], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "print(\"The four randomly-chosen numbers are:\", a,b,c,d)\n",
    "print(\"The size of the 4 randomly-chosen images are: \",X_train[a].shape, X_train[b].shape, \n",
    "                                                     X_test[c].shape, X_test[d].shape)\n",
    "print(\"The corresponding labels for the 4 images are:\", Y_train[a], Y_train[b], Y_train[c], Y_train[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (25000, 32, 32, 1)\n",
      "Training labels shape:  (25000, 10)\n",
      "Testing data shape:  (5000, 32, 32, 1)\n",
      "Test labels shape:  (5000, 10)\n",
      "Input shape:  (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "num_classes = 10\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Preprocessing: subtract the mean image\n",
    "train_mean = np.mean(X_train,axis=0)\n",
    "test_mean = np.mean(X_test,axis=0)\n",
    "X_train -= train_mean\n",
    "X_test -= test_mean\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)\n",
    "print(\"Input shape: \", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the VGG-11 model, VGG paper model A\n",
    "# Use same padding since the input shape(32,32,3) for this project is significantly smaller than that in the paper(224,224,3)\n",
    "def VGG_model():\n",
    "    model = Sequential()\n",
    "    regu = 5e-4\n",
    "    model.add(Conv2D(64,(3,3), input_shape=input_shape, padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "#     learning_rate = 0.01\n",
    "#     decay = learning_rate/epochs\n",
    "#     adam_customized = keras.optimizers.Adam(lr=learning_rate,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 28,186,634\n",
      "Trainable params: 28,164,746\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the vgg model\n",
    "vgg11_model = VGG_model()\n",
    "vgg11_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify the hyperparameters here\n",
    "batch_size = 512\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (25000, 32, 32, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (5000, 32, 32, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/48 [==============================] - 3658s - loss: 4.0989 - acc: 0.4675 - val_loss: 5.1932 - val_acc: 0.2719\n",
      "Epoch 2/10\n",
      "49/48 [==============================] - 3530s - loss: 2.2462 - acc: 0.8694 - val_loss: 9.0034 - val_acc: 0.1492\n",
      "Epoch 3/10\n",
      "49/48 [==============================] - 7648s - loss: 1.4177 - acc: 0.9491 - val_loss: 8.9298 - val_acc: 0.1341\n",
      "Epoch 4/10\n",
      "49/48 [==============================] - 6552s - loss: 0.9030 - acc: 0.9748 - val_loss: 5.9667 - val_acc: 0.1506\n",
      "Epoch 5/10\n",
      "49/48 [==============================] - 6471s - loss: 0.6186 - acc: 0.9803 - val_loss: 3.0464 - val_acc: 0.3353\n",
      "Epoch 6/10\n",
      "49/48 [==============================] - 6433s - loss: 0.4836 - acc: 0.9813 - val_loss: 2.8168 - val_acc: 0.4049\n",
      "Epoch 7/10\n",
      "49/48 [==============================] - 6425s - loss: 0.3491 - acc: 0.9887 - val_loss: 1.0378 - val_acc: 0.7270\n",
      "Epoch 8/10\n",
      "49/48 [==============================] - 6417s - loss: 0.2884 - acc: 0.9868 - val_loss: 1.0302 - val_acc: 0.7407\n",
      "Epoch 9/10\n",
      "49/48 [==============================] - 6442s - loss: 0.2178 - acc: 0.9919 - val_loss: 0.9265 - val_acc: 0.7741\n",
      "Epoch 10/10\n",
      "49/48 [==============================] - 7521s - loss: 0.1684 - acc: 0.9931 - val_loss: 0.4998 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "# define data preparation\n",
    "datagen_train = ImageDataGenerator(zca_whitening=True)\n",
    "datagen_test = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen_train.fit(X_train)\n",
    "datagen_test.fit(X_test)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = vgg11_model.fit_generator(datagen_train.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                          steps_per_epoch=len(X_train)/batch_size, epochs=epochs, \n",
    "                          validation_data=datagen_test.flow(X_test,Y_test),validation_steps=len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation CONV: summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple_conv: summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
