{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set up for the project\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Testing data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Get the original dimension of dataset\n",
    "(X_train_orig, Y_train), (X_test_orig, Y_test) = mnist.load_data()\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Testing data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Cut the traning and testing set by 1/10 to reduce operation time\n",
    "num_train = 60000\n",
    "mask_train = range(num_train)\n",
    "X_train_orig = X_train_orig[mask_train]\n",
    "Y_train = Y_train[mask_train]\n",
    "\n",
    "num_test = 10000\n",
    "mask_test = range(num_test)\n",
    "X_test_orig = X_test_orig[mask_test]\n",
    "Y_test = Y_test[mask_test]\n",
    "\n",
    "print(\"Training data shape: \", X_train_orig.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test_orig.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAACFCAYAAADCQpQyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n32HHR0S+839Lu9ZmaKBy6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f3cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shape is:  (28, 28)\n",
      "The new image shape is:  (32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Resize the images to 32*32 as required\n",
    "# But why resize it: Because if we follow the vgg network, the dimension decreases dramatically to 1x1 at last\n",
    "# Visualize and verify the functionality of imresize\n",
    "a = random.randint(0,num_train)\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train_orig[a])\n",
    "newimg = imresize(X_train_orig[a],(32,32))\n",
    "plt.subplot(222)\n",
    "plt.imshow(newimg)\n",
    "plt.show()\n",
    "print(\"The original shape is: \", X_train_orig[a].shape)\n",
    "print(\"The new image shape is: \", newimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four randomly-chosen numbers are: 9980 33684 5865 4917\n",
      "The size of the 4 randomly-chosen images are:  (32, 32) (32, 32) (32, 32) (32, 32)\n",
      "The corresponding labels for the 4 images are: 4 1 9 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG3dJREFUeJzt3XmMVeX5B/DvI4KswiA4jMPespRUAQsU+GFFgSq1qca0\nBps2tLHQpJu2TYMx8Y8mbWL/0TZt0oSicWoNVJQUbBuRIra4lFWoZVA2QZZhkUUQBASe3x9zeOa5\n07lwuPeec++57/eTNH7nznLfCc+8Pe95lyOqCiKikFxV7gYQEaWNHR8RBYcdHxEFhx0fEQWHHR8R\nBYcdHxEFhx0fEQWnqI5PRO4UkXdFZJuIPFyqRhGVG2u7ukmhC5hFpB2ALQCmAdgDYA2A+1W1sXTN\nI0ofa7v6XV3E944DsE1VdwCAiCwAcDeAvMUhItwmUjk+UNXe5W5Ehbqi2mZdV5RYdV3MULcewG73\n8Z7oNcqGXeVuQAVjbWdXrLou5oovFhGZDWB20u9DlCbWdbYV0/HtBdDPfdw3ei2Hqs4FMBfgkIAy\n47K1zbrOtmKGumsADBGRQSLSAcAMAEtK0yyismJtV7mCr/hU9ZyI/ADAUgDtADylqptK1jKiMmFt\nV7+Cl7MU9GYcElSSdao6ptyNqAas64oSq665c4OIgsOOj4iCw46PiILDjo+IgsOOj4iCk/jODQL6\n9+9v+YYbbrC8c+dOy/v370+zSUQQEcvXX399zudGjBhheceOHZb37dtn+ZNPPkmwdcniFR8RBYcd\nHxEFJ/ihbvv27S337NnTck1NjeVdu1oOfDh9+nTO9+dbAH7NNddYnjhxouXbbrvN8vz58y1zqEtp\nu+qqluuefv365Xzue9/7nuXVq1dbXrRokeXt27cn2Lpk8YqPiILDjo+IgsOOj4iCE+Q9Pn9vo76+\n5WDdqVOnWh48eLDl3/zmN5bPnDmT87Py3ePr0aOH5ZEjR1q+5ZZbLK9Zs8byq6++GqfpRKnwNTt2\n7FjLfjkL7/EREWUIOz4iCk4wQ12/Sv3aa6+1/LWvfc3yrFmzLP/jH/+wfOjQIcsXLlyI9X5+qOtz\nXV2d5SlTplieN29erJ9LlDa/tKtLly5lbEnp8IqPiILDjo+IghPMULd375ZnDP/whz+0/I1vfMPy\ne++9Z7mhocFy3OGt16lTJ8udO3e+4u8nSppf3eBvxwBAu3bt0m5OqnjFR0TBYcdHRMEJZqj7la98\nxfL06dMtf/jhh5YXL15s+T//+U9R79exY8c2M1GluPrqlj//L37xizmf8ysfqtFlr/hE5CkROSgi\n/3Wv9RSRZSKyNfpvzaV+BlElYm2HK85Q92kAd7Z67WEAy1V1CIDl0cdEWfM0WNtBuuxQV1X/JSID\nW718N4DJUW4A8CqAOSVsV0mMGdPyXOG77rrL8qBBgyz//e9/t/zSSy9Z/vjjj4t676amJst+fyNV\njizXdqH8bK0/f7L1ULdbt26WW+9PrwaFTm7UqurFv+z9AGpL1B6icmNtB6DoyQ1VVRFp+4gSACIy\nG8DsYt+HKG2Xqm3WdbYV2vEdEJE6VW0SkToAB/N9oarOBTAXAC7VQRbD78P1M1X33nuv5dGjR1v2\nC5VfeeWVNl8v1kcffdRmpooXq7bTqOskdO3a1fIXvvAFywMHDsz5ug4dOlj2Kx+y/GQ1r9Ch7hIA\nM6M8E8DiS3wtUZawtgMQZznLfABvAhgmIntE5AEAjwGYJiJbAUyNPibKFNZ2uOLM6t6f51NT8rye\nOj+8vfXWWy1PmzbNst876087XrlypeWzZ88m1MIWfn+kf8Kb/x3OnTuXeDsoG7Vdav7v4KabbrLs\nnwoI5N4+8reA/BFtWcYta0QUHHZ8RBSczO7V9Zfi/lRYf4ry0KFDLW/YsMHyP//5T8vvv/9+Uk1s\nk58t8wtI/e9w/Phxy/keZkSUlh07dljmUJeIKKPY8RFRcDI71PWzUMOGDbM8fvx4y344/OKLL1pe\nt26d5TRmcj1/RJV/8JA/IfrEiROWOdSlcvP71qtl3y6v+IgoOOz4iCg4mR3qXn/99ZYfeughy336\n9LG8evVqy2+88YZlf2RUOfkFzAMGDLB88GDL9lC/z7eQhx4RFauxsdFypfztFItXfEQUHHZ8RBSc\nzAx1/R5XIPdhKH7PoT9h9i9/+YvlnTt3Wq6UmVJ/EvTChQst+xnoRx991HLai62JAODAgQOW/RFV\nWcYrPiIKDjs+IgoOOz4iCk5V3OP71Kc+Zdnv1vBPNzt16lTB7+1/ZuuHg/vdF2PHjrXsn/A2efLk\nNn+u/5387+MPV+jcuXObXw9weQtdue7du1v+8pe/bNkvrWrt/Pnzlivl/nixeMVHRMFhx0dEwcnM\nUNcPN4HcYZ8/487vdDh27Jhlf7nuz77zT53yy0v8sNUfC++f1gbk7hTxu0n8Ed/+4cz+UAR/xLw/\nOOH3v/+9Zb+UoFqGGVQ+/ilpvrb8QR9A7rIwfyvJ1/ju3buTaGIqeMVHRMFhx0dEwcnMULf1MO/0\n6dOWP/jgA8t+6DpjxgzLfujqZ1Cvu+46y7169bI8ePBgy35Y7X8+kHs+2caNGy2vX7/esh9aT5nS\n8gAvP7R+/fXXLS9btsyyXynPoS4Vy9eyP9Oy9a0kz9+S8beMsizOc3X7icgKEWkUkU0i8mD0ek8R\nWSYiW6P/1iTfXKLSYW2HK85Q9xyAn6rqCADjAXxfREYAeBjAclUdAmB59DFRlrC2AxXngeJNAJqi\nfEJENgOoB3A3gMnRlzUAeBXAnERaif9drOtnpP74xz9avuOOOyxPmjTJ8rhx4yz7oae/dPdD5sOH\nD1vetWuX5e3bt+e048iRI5b98NafYeZnwvxQ2Z/Bd/LkScs8gy8dlVLbafIrIPr372+59eJ4z/+t\n+ScAZtkVTW6IyEAAowGsAlAbFQ4A7AdQW9KWEaWItR2W2JMbItIVwAsAHlLV4/5mqKqqiLR5511E\nZgOYXWxDiZJSSG2zrrMtVscnIu3RXBjPquqi6OUDIlKnqk0iUgfgYFvfq6pzAcyNfk7B05Kth3x+\nH+7jjz9u2Q9L/axpvr2I/jLen3fnZ1P9bG3rM/HiDEX97NnevXvbfN3PIvvFo5SsQmu7VHWdBj+M\n9XvN/cL6S83q+hUUfgF0lsWZ1RUATwLYrKqPu08tATAzyjMBLC5984iSw9oOV5wrvv8D8E0Ab4vI\nhui1RwA8BuA5EXkAwC4A9yXTRKLEsLYDFWdW9zUA+a6Dp+R5PXF+NtYPe3/729+WozmX5IcaPvs9\nwPX19ZYvNeyg0qnU2i41v2+8trZlnsbf/gmt5rhljYiCw46PiIKTmb26WeZnb1vv9SVKWk1Ny447\n/0TCkGuRV3xEFBx2fEQUHA51U+AXQ/sF00RUHrziI6LgsOMjouBwqJsCf3Iyj5mitPkHXB09etSy\nP1nZL6YPAa/4iCg47PiIKDhhXd+WiR9S+JOdt2zZYnnz5s2Wq+WBLlQZ/POl/UOt5s2bZ/nb3/52\nzvf4lQj+dPBquVXDKz4iCg47PiIKDjs+IgqOpPmQ6ko/ojsp/twz/2Qrv2HcH0nvn9bm7w+W2DpV\nHZPUDw9JluraHz0/dOhQy7fcckvO1506dcryihUrLPtHL1To/b5Ydc0rPiIKDjs+IgoOh7rh4lC3\nRFjXFYVDXSKitrDjI6LgsOMjouDEeaB4RxFZLSIbRWSTiPw8en2QiKwSkW0i8mcR6ZB8c4lKh7Ud\nrjhXfGcA3K6qIwGMAnCniIwH8CsAT6jqpwEcBfBAcs0kSgRrO1CX7fi02UfRh+2j/ymA2wE8H73e\nAOCeRFpIlBDWdrhi3eMTkXYisgHAQQDLAGwHcExVL24r2AOgPpkmEiWHtR2mWB2fqp5X1VEA+gIY\nB2B43DcQkdkislZE1hbYRqLEFFrbrOtsu6JZXVU9BmAFgAkAeojIxfP8+gLYm+d75qrqGC6WpUp2\npbXNus62OLO6vUWkR5Q7AZgGYDOai+Sr0ZfNBLA4qUYSJYG1Ha44JzDXAWgQkXZo7iifU9W/ikgj\ngAUi8gsAbwF4MsF2EiWBtR2otPfqHgJwEsAHqb1p5eiFyvq9B6hq73I3ohpEdb0LlfdvnJZK+r1j\n1XWqHR8AiMjaEO+LhPp7hyTUf+Ms/t7cskZEwWHHR0TBKUfHN7cM71kJQv29QxLqv3Hmfu/U7/ER\nEZUbh7pEFBx2fEQUnFQ7PhG5U0Tejc45ezjN906TiPQTkRUi0hid8/Zg9HpPEVkmIluj/9aUu61U\nPNZ19uo6tXt80er4LWjeFrQHwBoA96tqYyoNSJGI1AGoU9X1ItINwDo0H230LQBHVPWx6A+kRlXn\nlLGpVCTWdTbrOs0rvnEAtqnqDlU9C2ABgLtTfP/UqGqTqq6P8gk07/+sR/Pv2xB9Gc95qw6s6wzW\ndZodXz2A3e7jIM45E5GBAEYDWAWgVlWbok/tB1BbpmZR6bCuM1jXnNxIkIh0BfACgIdU9bj/nDbf\nY+BaIsqcaqjrNDu+vQD6uY/znuFXDUSkPZqL41lVXRS9fCC6T3LxfsnBcrWPSoZ1ncG6TrPjWwNg\nSPQEqw4AZgBYkuL7p0ZEBM1HGW1W1cfdp5ag+Xw3gOe8VQvWdQbrOu1jqb4E4NcA2gF4SlV/mdqb\np0hEJgFYCeBtABeilx9B8/2Q5wD0R/MxRvep6pGyNJJKhnWdvbrmljUiCg4nN4goOEV1fKGsWKfw\nsLarW8FD3ZBWrFNYWNvVL87DhvKxFesAICIXV6znLQ4R4Q3FyvEBn7mR1xXVNuu6osSq62KGukGu\nWK8iu8rdgArG2s6uWHVdzBVfLCIyG8DspN+HKE2s62wrpuOLtWJdVeciOpqaQwLKiMvWNus624oZ\n6gazYp2Cw9qucgVf8anqORH5AYClaFmxvqlkLSMqE9Z29Ut7yxqHBJVjXdYeAl2pWNcVJVZdc+cG\nEQWHHR8RBYcdHxEFhx0fEQWHHR8RBSfxnRtZ0nzAbLOuXbtavvHGGy3X1uY+R+Waa66x3KVLF8uH\nDh2yvGXLFsu7d7fshDp58mSRLSZKRp8+fSz7+j98+LBlX9cfffRROg0rEV7xEVFw2PERUXCCH+r6\n4W2vXr0sT5o0yfLXv/51y8OGDcv5/o4dO1quqamxvHPnTssvvfSS5aVLl1resGGD5awNFai6ff7z\nn7f8ne98x7Kv2aefftpy1uqXV3xEFBx2fEQUHHZ8RBSc4O/x9ejRw/KUKVMsz5kzx/LIkSMt+3uC\nAJDvkIfrrrvOsl8Cc8MNN1j+05/+ZPnNN9+0fObMmcv+fKIk+Xt8Y8a07Pk/evSoZb/kK2t4xUdE\nwWHHR0TBCXKo265dO8u33nqr5R//+MeW/fC2WH379rXsl8YMHz7c8k9+8hPL69evt/zJJ5+UrB1E\ncfXs2dNy+/btLfvbMD5nDa/4iCg47PiIKDhBDnX9ENPP5I4YMSLx9/aHGowePdry7373O8szZsyw\n/P7771vmsJfS4nckffzxx5Y3btxoeevWram2qZR4xUdEwWHHR0TBCWao269fy/OhZ86cafnee++1\n3Llz5za/9+zZs5YXLlyY87nx48e3+R7vvvtum9/vh9n+/QYOHGi5W7dulq+6iv/fRMnwteUX1gPA\nZz7zGct+ofL58+fbzFlz2b8qEXlKRA6KyH/daz1FZJmIbI3+W3Opn0FUiVjb4YpzOfE0gDtbvfYw\ngOWqOgTA8uhjoqx5GqztIF12qKuq/xKRga1evhvA5Cg3AHgVwBxUMH++ns9+H23rfbgX+YWafvYV\nAI4dO2b5nnvusexnvJqamixfe+21locMGWLZz/b6Y7/9z8nygtFKVC21XSi/MNnf8gGAAQMGWO7Q\noUNqbUpLoff4alX14l/zfgC1+b5QRGYDmF3g+xClLVZts66zrejJDVVVEcl7hIiqzgUwFwAu9XVE\nleZStc26zrZCO74DIlKnqk0iUgfgYCkbVSp+1nTUqFGW/eyrn9nys6/+aVLbt2+33NjYmPMeL774\nomU/PFi3bp1lPxyeOHFim231w47p06db3rRpk2W/kBQALly40ObPoqJkorZLwdf+oEGDcj7nFzD7\nRfT+6YFZVuhaiSUALq4JmQlgcWmaQ1R2rO0AxFnOMh/AmwCGicgeEXkAwGMAponIVgBTo4+JMoW1\nHa44s7r35/nUlDyvVww/rLz55pst+1OX/UzpO++8Y3nJkiVtvt56ZnXt2rWWX3vtNct+SNypU6fL\nttUPde+66y7LzzzzjOX9+/fnfA+HusXJcm2Xgj+ezS9YBnJncn2N+6cHZhm3BRBRcNjxEVFwqnqv\n7h133GHZHznVpUsXy35P7YIFCyz/4Q9/sHzkyJG87+E/98Ybb1g+eLBlMjDOcVd+hm3w4MGWu3fv\nbtkPTQAeU0VXzteZ/zuYMGFCztf5B4T7uvYzvFnGKz4iCg47PiIKTlUMdf0e25qalsM0/J5Xvxf2\n3Llzlv1l/LPPPmv5UsPbfNasWWPZH9mTxsnORHH4vwNfl37BMpA7k+sX4/tbOFnGKz4iCg47PiIK\nTlUMdf0C4fvvb1mT6p+Z64fA+/bts/zee+9Z9ntqC8Fjo6jS9erVy/KsWbMstz56yu9br8aF8rzi\nI6LgsOMjouBkdqjrZ6eGDh1q+dFHH7Xcu3fvNr939erVlleuXGn55MmTpWxim/wMdL4Tn/2ssx9m\nqPLYNyqOX7T8uc99znLr4ezzzz9v2d8Oqha84iOi4LDjI6LgsOMjouBk9h6f32ztH3jsl7b4e2ib\nN2+27I+L9yvUS3kPzbfv6quvbvN1/37+wIGXX37Z8u7duy37JQZExfK1uGfPnpzPvfXWW5aLXeZV\niXjFR0TBYcdHRMHJ7FDXP5jbn7vnj3D3/BPKjh49ajmpJSx1dXWWb7zxRssDBw5s8+v9coK9e/da\n9u3mchYqhL8VNHz4cMt+udfChQtzvscfRuAP3KgWvOIjouCw4yOi4GR2qOs3Vfvho5+p8vyQManZ\nUf8A8ylTWh7U5Yfifoju+d0a/mlt/ghworj830F9fb1lf3CHr9cdO3bkfH+1H7gR57m6/URkhYg0\nisgmEXkwer2niCwTka3Rf2su97OIKglrO1xxhrrnAPxUVUcAGA/g+yIyAsDDAJar6hAAy6OPibKE\ntR2oOA8UbwLQFOUTIrIZQD2AuwFMjr6sAcCrAOYk0soS8As0/axusfyM2U033WTZPxTcv+754YRf\nYP3vf//b8qlTp0rSTvpf1VLbbfGL5v1T+/xtF7+S4J133sn5/tOnTyfYuvK7ont8IjIQwGgAqwDU\nRoUDAPsB1Ob5ntkAZhfeRKLkXWlts66zLfasroh0BfACgIdU9bj/nDYvMGtzkZmqzlXVMao6pqiW\nEiWkkNpmXWdbrCs+EWmP5sJ4VlUXRS8fEJE6VW0SkToAiT5+qfXZdf7h2vn253p+JtfPoMbhZ8ha\nn/E3ceJEy9OnT7c8duxYy/4JVn5Prj/n7JlnnrHsF49eaVvpylRCbSehZ8+elkeOHGnZL2D2t1dW\nrVqV8/1pnE1ZTnFmdQXAkwA2q+rj7lNLAMyM8kwAi0vfPKLksLbDFeeK7/8AfBPA2yKyIXrtEQCP\nAXhORB4AsAvAfck0kSgxrO1AxZnVfQ1A2+NHYEqe10uu9RDWHz3fo0ePvF93kZ9ZHTJkiOVt27ZZ\nzjd87t69u+Xbbrst5+d+97vfbfPn+gXWfvbMD2OXLl1qed68eZb9jBr35yanUmq7VHz9fvazn7Xs\nFy37I6b88fJHjhzJ+VnV+GQ1j1vWiCg47PiIKDiZ3avrj8rxM1D5hoZ+ODxhwgTLfsjsh7R+aDx+\n/HjLw4YNy/m5+fYG+3b4/bZ+9qyhocGy30tMVAhfv6NGjbJ88803W/ZD2mXLllkObfUAr/iIKDjs\n+IgoOJkZ6raeZTp+vGWBvX9g0NSpUy3705j79etnedasWZb9Jb4ftvoZsnwZyD+09jOzf/vb3yw/\n8cQTlt9+++02v5eoEH5Prh/e+hUGr7/+umX/d8OhLhFRlWPHR0TBycxQtzU/U7py5UrLP/vZz9r8\nej+M9TO5PhfC7wF+5ZVXLC9atMiyb9+uXbssV+NDXKh8/Eyuf8DV9u3bLc+fP99ytZ+yfCm84iOi\n4LDjI6LgZHao62dN/ezogw8+aPlHP/qRZb/w2B8Tlc+HH35oecWKFZb9sVIA8PLLL1veuHGjZT+k\n9YtGObylpPi/iX379ln2x5/5071D3gfOKz4iCg47PiIKDjs+IgpOZu/x+Z0c/qlpL7zwgmV/9lif\nPn0s+5Xs+finm/kjuluvcG9sbLR84sQJyyHfP6Hy8PfvDh8+bNn/ffi/iZDxio+IgsOOj4iCI2kO\nyUSE47/KsY6PRiwN1nVFiVXXvOIjouCw4yOi4LDjI6LgxHmgeEcRWS0iG0Vkk4j8PHp9kIisEpFt\nIvJnEbn8GhGiCsLaDlecK74zAG5X1ZEARgG4U0TGA/gVgCdU9dMAjgJ4ILlmEiWCtR2oy3Z82uzi\n4Xfto/8pgNsBXHwicQOAexJpIVFCWNvhinWPT0TaicgGAAcBLAOwHcAxVb24jWEPgPo83ztbRNaK\nyNq2Pk9UToXWNus622J1fKp6XlVHAegLYByA4XHfQFXnquoYrhmjSlRobbOus+2KZnVV9RiAFQAm\nAOghIhf3+vYFsLfEbSNKDWs7LHFmdXuLSI8odwIwDcBmNBfJV6MvmwlgcVKNJEoCaztccU5nqQPQ\nICLt0NxRPqeqfxWRRgALROQXAN4C8GSC7SRKAms7UGnv1T0E4CSAD1J708rRC5X1ew9Q1d7lbkQ1\niOp6Fyrv3zgtlfR7x6rrVDs+ABCRtSHeEA719w5JqP/GWfy9uWWNiILDjo+IglOOjm9uGd6zEoT6\ne4ck1H/jzP3eqd/jIyIqNw51iSg4qXZ8InKniLwbHffzcJrvnSYR6SciK0SkMTru6MHo9Z4iskxE\ntkb/rSl3W6l4rOvs1XVqQ91okegWNK+O3wNgDYD7VbXxkt+YQSJSB6BOVdeLSDcA69B8wse3ABxR\n1ceiP5AaVZ1TxqZSkVjX2azrNK/4xgHYpqo7VPUsgAUA7k7x/VOjqk2quj7KJ9C8Daoezb9vQ/Rl\nPO6oOrCuM1jXaXZ89QB2u4/zHmVVTURkIIDRAFYBqFXVpuhT+wHUlqlZVDqs6wzWNSc3EiQiXQG8\nAOAhVT3uP6fN9xg4pU6ZUw11nWbHtxdAP/dxVR/3IyLt0Vwcz6rqoujlA9F9kov3Sw6Wq31UMqzr\nDNZ1mh3fGgBDoge5dAAwA8CSFN8/NSIiaD7RY7OqPu4+tQTNxxwBPO6oWrCuM1jXaZ/O8iUAvwbQ\nDsBTqvrL1N48RSIyCcBKAG8DuBC9/Aia74c8B6A/mk/zuE9Vj5SlkVQyrOvs1TV3bhBRcDi5QUTB\nYcdHRMFhx0dEwWHHR0TBYcdHRMFhx0dEwWHHR0TBYcdHRMH5fxgL1bMLsWfxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1185ce438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resize all images in training and test sets\n",
    "X_train = np.zeros((num_train,32,32))\n",
    "X_test = np.zeros((num_test,32,32))\n",
    "\n",
    "for i in range(num_train):\n",
    "    X_train[i] = imresize(X_train_orig[i],(32,32))\n",
    "\n",
    "for j in range(num_test):\n",
    "    X_test[j] = imresize(X_test_orig[j],(32,32))\n",
    "\n",
    "# Test with some random images\n",
    "a = random.randint(0,num_train)\n",
    "b = random.randint(0,num_train)\n",
    "c = random.randint(0,num_test)\n",
    "d = random.randint(0,num_test)\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[a], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[b], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_test[c], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_test[d], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "print(\"The four randomly-chosen numbers are:\", a,b,c,d)\n",
    "print(\"The size of the 4 randomly-chosen images are: \",X_train[a].shape, X_train[b].shape, \n",
    "                                                     X_test[c].shape, X_test[d].shape)\n",
    "print(\"The corresponding labels for the 4 images are:\", Y_train[a], Y_train[b], Y_train[c], Y_train[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 32, 32, 1)\n",
      "Training labels shape:  (60000, 10)\n",
      "Testing data shape:  (10000, 32, 32, 1)\n",
      "Test labels shape:  (10000, 10)\n",
      "Input shape:  (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "num_classes = 10\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Preprocessing: subtract the mean image\n",
    "train_mean = np.mean(X_train,axis=0)\n",
    "test_mean = np.mean(X_test,axis=0)\n",
    "X_train -= train_mean\n",
    "X_test -= test_mean\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Training labels shape: \", Y_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", Y_test.shape)\n",
    "print(\"Input shape: \", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify the hyperparameters here\n",
    "batch_size = 512\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_conv_net():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 892,650\n",
      "Trainable params: 891,242\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_conv = simple_conv_net()\n",
    "simple_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 455s - loss: 0.1246 - acc: 0.9614 - val_loss: 0.1027 - val_acc: 0.9672\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 462s - loss: 0.0298 - acc: 0.9914 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 456s - loss: 0.0193 - acc: 0.9941 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 453s - loss: 0.0116 - acc: 0.9969 - val_loss: 0.0242 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 486s - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 496s - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0218 - val_acc: 0.9936\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 509s - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0213 - val_acc: 0.9930\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 505s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0260 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "36352/60000 [=================>............] - ETA: 187s - loss: 0.0041 - acc: 0.9991"
     ]
    }
   ],
   "source": [
    "simpleConv_history = simple_conv.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=epochs,batch_size=batch_size)\n",
    "simpleConv_scores = simple_conv.evaluate(X_test,Y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple_conv: list all data in history\n",
    "print(simpleConv_history.history.keys())\n",
    "\n",
    "# Simple_conv: summarize history for accuracy\n",
    "plt.plot(simpleConv_history.history['acc'])\n",
    "plt.plot(simpleConv_history.history['val_acc'])\n",
    "plt.title('SimpleConv model accuracy')\n",
    "plt.ylabel('SimpleConv accuracy')\n",
    "plt.xlabel('SimpleConv epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple_conv: summarize history for loss\n",
    "plt.plot(simpleConv_history.history['loss'])\n",
    "plt.plot(simpleConv_history.history['val_loss'])\n",
    "plt.title('SimpleConv model loss')\n",
    "plt.ylabel('SimpleConv loss')\n",
    "plt.xlabel('SimpleConv epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the VGG-11 model, VGG paper model A\n",
    "# Use same padding since the input shape(32,32,3) for this project is significantly smaller than that in the paper(224,224,3)\n",
    "def VGG_model():\n",
    "    model = Sequential()\n",
    "    regu = 5e-4\n",
    "    model.add(Conv2D(64,(3,3), input_shape=input_shape, padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regu)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "#     learning_rate = 0.01\n",
    "#     decay = learning_rate/epochs\n",
    "#     adam_customized = keras.optimizers.Adam(lr=learning_rate,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vgg model\n",
    "vgg11_model = VGG_model()\n",
    "vgg11_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vgg model\n",
    "vgg_history = vgg11_model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=epochs,batch_size=batch_size)\n",
    "vgg_scores = vgg11_model.evaluate(X_test,Y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG: list all data in history\n",
    "print(vgg_history.history.keys())\n",
    "\n",
    "# VGG: summarize history for accuracy\n",
    "plt.plot(vgg_history.history['acc'])\n",
    "plt.plot(vgg_history.history['val_acc'])\n",
    "plt.title('vgg model accuracy')\n",
    "plt.ylabel('vgg accuracy')\n",
    "plt.xlabel('vgg epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG: summarize history for loss\n",
    "plt.plot(vgg_history.history['loss'])\n",
    "plt.plot(vgg_history.history['val_loss'])\n",
    "plt.title('VGG model loss')\n",
    "plt.ylabel('VGG loss')\n",
    "plt.xlabel('VGG epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import os\n",
    "project_dir = os.getcwd()\n",
    "model_dir = project_dir + \"/models/\"\n",
    "vgg_model_loc = model_dir + \"vgg11.h5\"\n",
    "vgg_json_loc = model_dir + \"vgg11.json\"\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "vgg11_model_json = vgg11_model.to_json()\n",
    "with open(vgg_json_loc,\"w\") as json_file:\n",
    "    json_file.write(vgg11_model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "vgg11_model.save_weights(vgg_model_loc)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(vgg_json_loc,\"r\")\n",
    "loaded_vgg_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_vgg11 = model_from_json(loaded_vgg_json)\n",
    "# load weights into new model\n",
    "loaded_vgg11.load_weights(vgg_model_loc)\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vgg11.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "scores = loaded_vgg11.evaluate(X_test,Y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (loaded_vgg11.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
